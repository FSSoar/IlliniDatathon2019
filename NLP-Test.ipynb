{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1 = 'data/SentimentData/amazon_cells_labelled.txt'\n",
    "PATH2 = 'data/SentimentData/imdb_labelled.txt'\n",
    "PATH3 = 'data/SentimentData/yelp_labelled.txt'\n",
    "\n",
    "amazon_data = pd.read_csv(PATH1, sep='\\t', header=None, names=['sentence', 'sentiment'])\n",
    "imdb_data = pd.read_csv(PATH2, sep='\\t', header=None, names=['sentence', 'sentiment'])\n",
    "yelp_data = pd.read_csv(PATH3, sep='\\t', header=None, names=['sentence', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = amazon_data\n",
    "total_data = total_data.append(imdb_data, ignore_index=True)\n",
    "total_data = total_data.append(yelp_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "train_data_full = [tuple(x) for x in total_data.values]\n",
    "train_data = train_data_full[:2000]\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training NLP classifier...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('training NLP classifier...')\n",
    "classifier = classifiers.NaiveBayesClassifier(train_data)\n",
    "classifier.train()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n",
      "result\n",
      "0.6754882030498195\n"
     ]
    }
   ],
   "source": [
    "print('classifying...')\n",
    "prob_dist = classifier.prob_classify(\"Stocks are terrible\")\n",
    "print('result')\n",
    "print(prob_dist.prob(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593582887700535"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.accuracy(train_data_full[2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '8b8428b3603940ef8485d39a6eb526f2'\n",
    "news = NewsApiClient(api_key=key)\n",
    "\n",
    "companies = {'Synchrony Financial': [],\n",
    "            '3M': [],\n",
    "            'Bayer': [],\n",
    "            'Honeywell': []}\n",
    "\n",
    "ARTICLE_COUNT = 5\n",
    "\n",
    "for company in companies:\n",
    "    query = company + \" News\"\n",
    "    all_articles = news.get_everything(q=query, from_param='2019-02-01',to='2019-02-02', language='en', sort_by='relevancy')\n",
    "    article_data = all_articles['articles']\n",
    "    for i in range(ARTICLE_COUNT):\n",
    "        try:\n",
    "            titlePlusSummary = article_data[i]['title'] + '. ' + article_data[i]['description']\n",
    "            companies[company].append(titlePlusSummary)\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Synchrony Financial': 1.3697317812082912, '3M': 1.5567991879540197, 'Bayer': 3.6251427205105813, 'Honeywell': 2.003248803329603}\n"
     ]
    }
   ],
   "source": [
    "# Open the choosen news articles and extract the title\n",
    "title_to_polarity = {}\n",
    "net_company_scores = {}\n",
    "for company in companies:\n",
    "    net_company_scores[company] = 0\n",
    "    count = 0\n",
    "    for summary in companies[company]:\n",
    "        try:\n",
    "            prob_1 = classifier.prob_classify(summary).prob(1)\n",
    "            title_to_polarity[summary] = prob_1\n",
    "            net_company_scores[company] += prob_1\n",
    "        except:\n",
    "            continue\n",
    "    if count:\n",
    "        net_company_scores[company] /= count\n",
    "\n",
    "print(net_company_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
