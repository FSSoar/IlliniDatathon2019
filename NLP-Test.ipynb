{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pattern.en import ngrams\n",
    "from textblob import TextBlob\n",
    "from textblob import classifiers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1 = 'data/SentimentData/amazon_cells_labelled.txt'\n",
    "PATH2 = 'data/SentimentData/imdb_labelled.txt'\n",
    "PATH3 = 'data/SentimentData/yelp_labelled.txt'\n",
    "\n",
    "amazon_data = pd.read_csv(PATH1, sep='\\t', header=None, names=['sentence', 'sentiment'])\n",
    "imdb_data = pd.read_csv(PATH2, sep='\\t', header=None, names=['sentence', 'sentiment'])\n",
    "yelp_data = pd.read_csv(PATH3, sep='\\t', header=None, names=['sentence', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = amazon_data\n",
    "total_data = total_data.append(imdb_data, ignore_index=True)\n",
    "total_data = total_data.append(yelp_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "train_data_full = [tuple(x) for x in total_data.values]\n",
    "train_data = train_data_full[:2000]\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training NLP classifier...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('training NLP classifier...')\n",
    "classifier = classifiers.NaiveBayesClassifier(train_data)\n",
    "classifier.train()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying...\n",
      "result\n",
      "0.6754882030498195\n"
     ]
    }
   ],
   "source": [
    "print('classifying...')\n",
    "prob_dist = classifier.prob_classify(\"Stocks are terrible\")\n",
    "print('result')\n",
    "print(prob_dist.prob(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593582887700535"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.accuracy(train_data_full[2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "# to search \n",
    "\n",
    "companies = {'Synchrony Financial': [],\n",
    "            '3M': [],\n",
    "            'Bayer': [],\n",
    "            'Honeywell': []}\n",
    "\n",
    "\n",
    "for company in companies:\n",
    "    query = company + \" News\"\n",
    "    for link in search(query, num=5, stop=1, pause=2): \n",
    "        companies[company].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "{'Synchrony Financial': 4.091920365875385, '3M': 3.2328777948018086, 'Bayer': 4.11913610995684, 'Honeywell': 4.265869258906456}\n"
     ]
    }
   ],
   "source": [
    "# Open the choosen news articles and extract the title\n",
    "title_to_polarity = {}\n",
    "net_company_scores = {}\n",
    "for company in companies:\n",
    "    net_company_scores[company] = 0\n",
    "    count = 0\n",
    "    for link in companies[company]:\n",
    "        count += 1\n",
    "        results = requests.get(link)\n",
    "        results_text = BeautifulSoup(results.text, 'html.parser')\n",
    "        try:\n",
    "            title = results_text.title.string\n",
    "            prob_1 = classifier.prob_classify(title).prob(1)\n",
    "            title_to_polarity[title] = prob_1\n",
    "            net_company_scores[company] += prob_1\n",
    "        except:\n",
    "            continue\n",
    "    if count:\n",
    "        net_company_scores[company] /= count\n",
    "\n",
    "print(net_company_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06000000000000001\n",
      "-0.34166666666666673\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
